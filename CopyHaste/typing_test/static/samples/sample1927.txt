
kQB_STOP = set(["10", "ten", "points", "name", ",", ")",
				"(", '"', ']', '[', ":", "ftp"])
paren_expression = re.compile('\s*\([^)]*\)\s*')
tokenizer = TreebankWordTokenizer().tokenize
stopwords = set(stopwords.words('english')) | kQB_STOP
valid_strings = set(ascii_lowercase) | set(str(x) for x in xrange(10)) | set([' '])
punct_tbl = dict.
						  if unicodedata.category(unichr(i)).startswith('P'))
def relu(x):
	return x * (x > 0)
def normalize(text):
	text = unidecode(text).lower().translate(maketrans(punctuation, ' '*len(punctuation)))
	text = paren_expression.sub("", text)
	text = " ".join(x for x in text.split() if x not in stopwords)
	return ''.join(x for x in text if x in valid_strings)
class DeepExtractor(FeatureExtractor):
	def 