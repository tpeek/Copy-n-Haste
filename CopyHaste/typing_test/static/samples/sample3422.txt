if __name__ == "__main__":
	if len(sys.argv) != 7:
		print(, file=sys.stderr)
		exit(-1)
	host = sys.argv[1]
	keyspace = sys.argv[2]
	cf = sys.argv[3]
	sc = SparkContext(appName="CassandraOutputFormat")
	conf = {"cassandra.output.thrift.address": host,
			"cassandra.output.thrift.port": "9160",
			"cassandra.output.keyspace": keyspace,
			"cassandra.output.partitioner.class": "Murmur3Partitioner",
			"cassandra.output.cql": "UPDATE " + keyspace + "." + cf + " SET fname = ?, lname = ?",
			"mapreduce.output.basename": cf,
			"mapreduce.outputformat.class": "org.apache.cassandra.hadoop.cql3.CqlOutputFormat",
			"mapreduce.job.output.key.class": "java.util.Map",
			"mapreduce.job.output.value.class": "java.util.List"}
	key = {"user_id": int(sys.argv[4])}
	sc.parallelize([(key, sys.argv[5:])]).saveAsNewAPIHadoopDataset(
		conf=conf,
		keyConverter="org.apache.spark.examples.pythonconverters.ToCassandraCQLKeyConverter",
		valueConverter="org.apache.spark.examples.pythonconverters.ToCassandraCQLValueConverter")
	sc.stop()