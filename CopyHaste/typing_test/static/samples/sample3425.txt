D = 10
def readPointBatch(iterator):
	strs = list(iterator)
	matrix = np.zeros((len(strs), D + 1))
	for i, s in enumerate(strs):
		matrix[i] = np.
	return [matrix]
if __name__ == "__main__":
	if len(sys.argv) != 3:
		print("Usage: logistic_regression <file> <iterations>", file=sys.stderr)
		exit(-1)
	print(, file=sys.stderr)
	sc = SparkContext(appName="PythonLR")
	points = sc.textFile(sys.argv[1]).mapPartitions(readPointBatch).cache()
	iterations = int(sys.argv[2])
	w = 2 * np.random.ranf(size=D) - 1
	print("Initial w: " + str(w))
	def gradient(matrix, w):
		Y = matrix[:, 0]
		X = matrix[:, 1:]
		return ((1.0 / (1.0 + np.exp(-Y * X.dot(w))) - 1.0) * Y * X.T).sum(1)
	def add(x, y):
		x += y
		return x
	for i in range(iterations):
		print("On iteration %i" % (i + 1))
		w -= points.map(lambda m: gradient(m, w)).reduce(add)
	print("Final w: " + str(w))
	sc.stop()