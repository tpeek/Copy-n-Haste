if __name__ == "__main__":
	sc = SparkContext(appName="SimpleTextClassificationPipeline")
	sqlContext = SQLContext(sc)
	LabeledDocument = Row("id", "text", "label")
	training = sc.parallelize([(0, "a b c d e spark", 1.0),
							   (1, "b d", 0.0),
							   (2, "spark f g h", 1.0),
							   (3, "hadoop mapreduce", 0.0)]) \
		.map(lambda x: LabeledDocument(*x)).toDF()
	tokenizer = Tokenizer(inputCol="text", outputCol="words")
	hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol="features")
	lr = LogisticRegression(maxIter=10, regParam=0.001)
	pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])
	model = pipeline.fit(training)
	Document = Row("id", "text")
	test = sc.parallelize([(4, "spark i j k"),
						   (5, "l m n"),
						   (6, "spark hadoop spark"),
						   (7, "apache hadoop")]) \
		.map(lambda x: Document(*x)).toDF()
	prediction = model.transform(test)
	selected = prediction.select("id", "text", "prediction")
	for row in selected.collect():
		print(row)
	sc.stop()