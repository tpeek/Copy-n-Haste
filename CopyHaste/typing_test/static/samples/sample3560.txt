DataStreamMonitoring)
logger = logging.getLogger('main')
def setup_model():
	ladder = LadderAE()
	input_type = TensorType('float32', [False, False])
	x = input_type('features')
	y = theano.tensor.lvector('targets')
	ladder.apply(x, y)
	return ladder
def train(ladder, batch_size=100, num_train_examples=50000,
		  num_epochs=150, lrate_decay=0.67):
	timestr = time.strftime("%Y_%m_%d_at_%H_%M")
	save_path = 'results/mnist_' + timestr
	log_path = os.path.join(save_path, 'log.txt')
	os.makedirs(save_path)
	fh = logging.FileHandler(filename=log_path)
	fh.setLevel(logging.DEBUG)
	logger.addHandler(fh)
	model = Model(ladder.costs.total)
	all_params = model.parameters
	print len(all_params)
	print all_params
	training_algorithm = GradientDescent(
		cost=ladder.costs.total, params=all_params,
		step_rule=Adam(learning_rate=ladder.lr))
	bn_updates = ComputationGraph([ladder.costs.class_clean]).updates
	training_algorithm.add_updates(bn_updates)
	monitored_variables = [
		ladder.costs.class_corr, ladder.costs.class_clean,
		ladder.error, training_algorithm.total_gradient_norm,
		ladder.costs.total] + ladder.costs.denois.values()
	train_data_stream, valid_data_stream = get_streams(
		num_train_examples, batch_size)
	train_monitoring = TrainingDataMonitoring(
		variables=monitored_variables,
		prefix="train",
		after_epoch=True)
	valid_monitoring = DataStreamMonitoring(
		variables=monitored_variables,
		data_stream=valid_data_stream,
		prefix="valid",
		after_epoch=True)
	main_loop = MainLoop(
		algorithm=training_algorithm,
		data_stream=train_data_stream,
		model=model,
		extensions=[
			train_monitoring,
			valid_monitoring,
			FinishAfter(after_n_epochs=num_epochs),
			SaveParams('valid_CE_clean', model, save_path),
			SaveLog(save_path, after_epoch=True),
			LRDecay(lr=ladder.lr,
					decay_first=num_epochs * lrate_decay,
					decay_last=num_epochs,
					after_epoch=True),
			Printing()])
	main_loop.run()
def evaluate(ladder, load_path):
	with open(load_path + '/trained_params_best.npz') as f:
		loaded = np.load(f)
		model = Model(ladder.costs.total)
		params_dicts = model.params
		params_names = params_dicts.keys()
		for param_name in params_names:
			param = params_dicts[param_name]
			slash_index = param_name.find('/')
			param_name = param_name[slash_index + 1:]
			assert param.get_value().shape == loaded[param_name].shape
			param.set_value(loaded[param_name])
	train_data_stream, valid_data_stream = get_streams(50000, 100)
	cg = ComputationGraph([ladder.costs.total])
	X, Y = train_data_stream.get_epoch_iterator().next()
	vertical_all = []
	lateral_all = []
	mixed_all = []
	for i in range(7):
		name_vertical = 'g_' + str(i) + "_a3"
		name_lateral = 'g_' + str(i) + "_a2"
		name_mixed = 'g_' + str(i) + "_a4"
		vertical_all += [np.mean(np.abs(list(
			params_dicts[name_vertical].get_value())))]
		lateral_all += [np.mean(np.abs(list(
			params_dicts[name_lateral].get_value())))]
		mixed_all += [np.mean(np.abs(list(
			params_dicts[name_mixed].get_value())))]
	N = len(vertical_all)
	bar_chart(N, vertical_all, lateral_all, mixed_all)
if __name__ == "__main__":
	load_path = '/u/pezeshki/ladder_network/results/mnist_best'
	logging.basicConfig(level=logging.INFO)
	ladder = setup_model()
	if load_path is None:
		train(ladder)
	else:
		evaluate(ladder, load_path)