xpath_tokenizer_re = re.compile(
	"("
	"'[^']*'|\"[^\"]*\"|"
	"::|"
	"//?|"
	"\.\.|"
	"\(\)|"
	"[/.*:\[\]\(\)@=])|"
	"((?:\{[^}]+\})?[^/\[\]\(\)@=\s]+)|"
	"\s+"
	)
def xpath_tokenizer(pattern, namespaces=None):
	for token in xpath_tokenizer_re.findall(pattern):
		tag = token[1]
		if tag and tag[0] != "{" and ":" in tag:
			try:
				prefix, uri = tag.split(":", 1)
				if not namespaces:
					raise KeyError
				yield token[0], "{%s}%s" % (namespaces[prefix], uri)
			except KeyError:
				raise SyntaxError("prefix %r not found in prefix map" % prefix)
		else:
			yield token
def get_parent_map(context):
	parent_map = context.parent_map
	if parent_map is None:
		context.parent_map = parent_map = {}
		for p in context.root.iter():
			for e in p:
	