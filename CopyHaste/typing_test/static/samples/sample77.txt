def dIVA_L(X, W_init=[], verbose=False) :
	cost_and_grad = set_para(X, verbose)
	N,R = X[0].shape[0], X[0].shape[1]
	K   = [x.shape[2] for x in X]
	P   = len(K)
	KK  = [sum(K[0:p+1]) for p in range(P)]
	KK.append(0)
	
	if W_init == [] :
		W_init = [np.random.rand(N,N,K[p]) for p in range(P)]
	W_init = mat_to_vec(W_init)
	W,d,i = fmin_l_bfgs_b(cost_and_grad, x0=W_init)
	if verbose :
		print "Optimization Finished"
	W = vec_to_mat(W,N,KK[-2])
	W_m = []
	for p in range(P) :
		W_m.append(W[:,:,KK[p-1]:KK[p]])
	
	return W_m, d, i
def set_para (X, verbose) :
	N,R = X[0].shape[0], X[0].shape[1]
	P   = len(X)
	K   = [x.shape[2] for x in X]
	KK  = [sum(K[0:p+1]) for p in range(P)]
	KK.append(0)
	
	def cost_and_grad(W) :
		W = vec_to_mat(W,N,KK[-2])
		W_m = []
		disper = []
		Y = [np.zeros((N,R,k)) for k in K]
		for p in range(P) :
			W_m.append(W[:,:,KK[p-1]:KK[p]])
			for k in range(K[p]) :
				Y[p][:,:,k] = dot(W_m[p][:,:,k], X[p][:,:,k])
		disper = [np.array([dot(Y[p][n,:,:].T, Y[p][n,:,:]) for n in range(N)]) for p in range(P)]
		A = [np.array([dot(pinv(disper[p][n,:,:]), Y[p][n,:,:].T) for n in range(N)]) for p in range(P)]
		YdY = np.zeros((N,R))
		for n in range(N) :
			YdY[n,:] = np