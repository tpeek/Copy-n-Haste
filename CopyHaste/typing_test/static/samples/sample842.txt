
start_time = time.time()
english_stemmer = nltk.stem.SnowballStemmer('english')
class StemmedTfidfCountVectorizer(TfidfVectorizer):
	def build_analyzer(self):
		analyzer = super(StemmedTfidfCountVectorizer, self).build_analyzer()
		return lambda doc: (english_stemmer.stem(w) for w in analyzer(doc))
vectorizer = StemmedTfidfCountVectorizer(min_df = 1, stop_words = 'english')
def create_ngram_model():
	tfidf_ngrams = TfidfVectorizer(ngram_range=(1, 3),
								   analyzer="word", binary=False)
	clf = svm.SVC(kernel='rbf')
	pipeline = Pipeline([('vect', tfidf_ngrams), ('clf', clf)])
	return pipeline
def train_model(SVMType, X, Y, name="SVM ngram", plot=False):
	cv = ShuffleSplit(
		n=len(X), n_iter=10, test_size=0.3, random_state=0)
	vectoriz